---
title: "Análise das viagens de taxi em Nova York"
author: "Rafael"
date: August 02, 2018
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(ggplot2)
theme_set(theme_minimal())
library(dplyr)
options(scipen = 999)
library(grid)
```


```{python echo=FALSE, include=FALSE}
# Manipulação de dados
import pandas as pd
import numpy as np
from datetime import datetime

# conexão com o banco de dados
import psycopg2
import configparser
conf = configparser.ConfigParser()
conf.read('dwh.cfg')
conn = psycopg2.connect("host={} dbname={} user={} password={} port={}".format(*conf['CLUSTER'].values()))
cur = conn.cursor()
conn.set_session(autocommit=True)

# Visualização de dados
import matplotlib.pyplot as plt
import seaborn as sns
```


## Introdução 

Antes de entrar um pouco nos insights que podem ser extraídos através do banco de dados é imporante detalhar um pouco o processo de criação do mesmo. 


1. O primeiro passo foi realizar uma exploração dos dados simples identificar potenciais problemas que poderiam ocorrer durante o processo de inserção dos dados em um banco de dados. Além de ser uma etapa muito importante para definição dos tipos de dados que serão utilizados. 


Ainda nessa etapa, foi realizada uma prototipação das consultas que seriam utilizadas para obter os dados solicitados do banco de dados. Essa etapa foi feita em uma amostra do banco de dados com 100.000 linhas (aleatóriamente selecionadas) para permitir uma comparação entre os resultados obtidos por meio de uma consulta no banco de dados e os resultados obtidos utilizando a biblioteca `pandas`

2. Automação do processo de ETL através da utilização de scripts de python e um script do bash (Shell):
  - create_tables.py
  - etl.py
  - sql_queries.py
  - cloud_config.py
  - automate_elt.sh
  
Para tanto, houve a criação de um script que através da obtenção de dois inputs do usuário: `AWS_ACCESS_KEY_ID` e `AWS_SECRET_ACCESS_KEY` permite automatizar todo o processo de criação de um cluster na Nuvem especificamente para esse projeto.

Após a criação desses cluster, um arquivo de configuração era criado para ser utilizado pelos

  
3. Nessa última etapa, através da utilização do cluster 
    
  
## Quesitos Mínimos  
  

### Distância média percorrida em viagens com no máximo dois passageiros

```{python echo=FALSE}
# Calculando a distância média
cur.execute("SELECT AVG(trip_distance) FROM trips WHERE passenger_count <= 2")
average_distance = cur.fetchone()


# coletando todos os registros relacionados a distância em corridas com até dois passageiros
cur.execute("SELECT trip_distance FROM trips WHERE passenger_count <= 2")
distribution = cur.fetchall()

# transformando o retorno do banco de dados em uma lista
distribution = [i[0] for i in distribution]
```



```{r include=TRUE, echo=FALSE}
distribution <- as.data.frame(py$distribution)
names(distribution) <- 'data'

distribution %>%
  ggplot(aes(data)) + geom_histogram(bins=30, fill='#32CD32') +
  geom_vline(xintercept = mean(distribution$data), color='red') +
  labs(title='Distância das corridas com até dois passageiros',
       x='distância em milhas',
       y='número de corridas')

```


### Quantidade total arrecada pelas três maiores empresas de taxi de Nova York


```{python}
cur.execute("""
SELECT nome, current, SUM(total_amount), COUNT(*)
FROM trips t
JOIN vendors v
ON t.vendor_id = v.vendor_id
WHERE total_amount IS NOT NULL
GROUP BY 1, 2
ORDER BY 3 DESC

""")
results = cur.fetchall()

# checando se o retorno possui o mesmo número de linhas que a tabela na cloud
assert sum([i[3] for i in results]) == 4000000

quantidade_arrecadada = [{'vendor': i[0], 'valor_total': i[2], 'numero_de_corridas': i[3]} for i in results]
quantidade_arrecadada = pd.DataFrame(quantidade_arrecadada)
```



```{r fig.width=8, fig.height=5}
quantidade_arrecadada <- as.data.frame(py$quantidade_arrecadada)

quantidade_arrecadada %>%
  # removendo a empresa que só possui uma corrida
  filter(valor_total > 100000) %>%
  
  # criando o gráfico
  ggplot(aes(reorder(vendor, -valor_total), valor_total, label=numero_de_corridas)) + 
  geom_bar(stat='identity', fill='purple') +
  scale_fill_gradientn(colours = c('blue','green')) +
  geom_text(size=4, position = position_stack(vjust=0.5)) +
  labs(title='Quantidade arrecadada pelas três maiores empresas', 
       x='empresas de taxi',
       y='total arrecadado')
```

```{r}
quantidade_arrecadada
```


### Distribuição mensal das corridas pagas em dinheiro nos últimos quatro anos


```{python include=FALSE, echo=FALSE}
cur.execute("""
SELECT EXTRACT(year FROM pickup_datetime) AS year,
    EXTRACT(month FROM pickup_datetime) AS month,
      COUNT(*)
FROM trips
WHERE payment_type = 'Cash'
GROUP BY 1, 2
""")
results = cur.fetchall()


# transformando os dados obtidos em um dataframe com o index igual a data.
distribuição = [{'data_mês': datetime.strptime(str(i[0]) + '-' + str(i[1]), '%Y-%m'), 
                 'numero_de_corridas': i[2]} for i in results]
distribuição = pd.DataFrame(distribuição)

```

```{python}
cur.execute("""
SELECT EXTRACT(year FROM pickup_datetime) AS year,
    EXTRACT(month FROM pickup_datetime) AS month,
      COUNT(*)
FROM trips
GROUP BY 1, 2
""")
results = cur.fetchall()


# transformando os dados obtidos em um dataframe com o index igual a data.
distribuição_all = [{'data_mês': datetime.strptime(str(i[0]) + '-' + str(i[1]), '%Y-%m'), 
                 'numero_de_corridas': i[2]} for i in results]
distribuição_all = pd.DataFrame(distribuição_all)
```




```{r}
distribuição <- as.data.frame(py$distribuição)
distribuição_all <- as.data.frame(py$distribuição_all)


plot1 <- distribuição %>%
  ggplot(aes(data_mês, numero_de_corridas)) + geom_line() + 
  labs(title='Distribuição das corridas pagas em dinheiro por mês (2009-2012)',
       x='mês e ano', y='número de corridas')

plot2 <- distribuição_all %>%
  ggplot(aes(data_mês, numero_de_corridas)) + geom_line() + 
  labs(title='Distribuição das corridas por mês (2009-2012)',
       x='mês e ano', y='número de corridas')



```


